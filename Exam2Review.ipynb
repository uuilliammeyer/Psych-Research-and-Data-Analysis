{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Welcome!</center></h1> This is a jupyternotebook created for the purpose of review for my upcoming psych2005 midterm. All material in this review guide is meant as review excersize or as a resource. Under no circumstances should this notebook be used in an accedmically dishonest fashion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Power and factors impacting it\n",
    "\n",
    "***Statistical Power:*** is the probability that the study will give a significant result *if the research hypothesis is true*.\n",
    "    - A lot of times we use statistical power to determine sample size.\n",
    "    - The probablility of getting a significant result if the research hypothesis is false is alpha.\n",
    "- Statistical power is determined by 2 main factors:\n",
    "    1. Effect size the research hypothesis predicts\n",
    "        - If your question is how can effect size impact power, first remember the formula $ d = \\frac{M_{1}-M_{2}}{\\sigma} $ \n",
    "        - The larger the expected **difference between the previous research and what you predict**, the larger the power levels. This can be interpreted as changing the numerator or a change in $ M_{1}-M_{2} $\n",
    "        - By the same resasoning a smaller **population standard deviation**, the larger the effect size and thus more power. This is a change in $ \\sigma $\n",
    "    2. Sample size\n",
    "        - The more people there are in a study the greater the power. Sample size effects power because the larger the sample size is, the smaller the standard deviation of the distribution of means becomes. This causes less overlpa between our null hypothesis curve and our research hypothesis curve.\n",
    "- Other factors include:\n",
    "    - One vs two tailed hypothesis testing\n",
    "        - Two tailed tests are harfer to get significant results with.\n",
    "    - Alpha or siginificance level\n",
    "        - More lenient significance levels like p<0.1 yield more power. However, thisn increase the chance of a type II error.\n",
    "    - The kind of testing procedure\n",
    "        - You probably won't be asked about this but just know that some kinds of experiments are more likely to yield significant results than others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using statistical power to evaluate results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Result is statistically  significant  | Sample size | Conclusion                                |\n",
    "|---------------------------------------|-------------|-------------------------------------------|\n",
    "| Yes                                   | Small       | Important result                          |\n",
    "| Yes                                   | Large       | May or may not have  practical importance |\n",
    "| No                                    | Small       | Inconclusive                              |\n",
    "| No                                    | Large       | Research hypothesis is probably false     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis testing is the main math based portion of this exam. There are three main tests we have learned: \n",
    "   - t tests for a single sample\n",
    "   - t tests for dependent means\n",
    "   - t tests for independent means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of differences between these tests. However, we must first ask *how do I pick the correct t test?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t test for a single sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one should be the most obvious about when to choose it. If you're hypothesis testing an you only have on sample, use the t test for a single sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> How do I conduct a t test for a single sample? </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The t test for a single sample follows the standard process of previous t tests.\n",
    "1. Restate the question as a research hypothesis and a null hypothesis about the populations.\n",
    "2. Determine the characteristics of the comparison distribution. \n",
    "    - The mean is the same as the known population mean\n",
    "    - There are three steps for calculating standard deviation\n",
    "        - Figure the estimated population variance:\n",
    "            - $ S^{2} = \\frac{SS}{df} $ \n",
    "                - if you don't have $SS$, $ SS = SD^{2} * N $ \n",
    "        - Figure the variance of the distribution of means:\n",
    "            - $ S^{2}_{M} = \\frac{S^{2}}{N} $ \n",
    "        - Figure the standard deviation of the distribution of means:\n",
    "            - $ S_{M} = \\sqrt{S^{2}_{M}} $\n",
    "    - Then pick the t distribution with $N-1 = df $ \n",
    "3. Determine the cut off sample score at which the null hypothesis is rejected. \n",
    "    - Choose: significance level, one vs two tailed test\n",
    "    - Look up the appropraite score on the t test table.\n",
    "4. Determine your samples score on the comparison distribution.\n",
    "    - $ t = \\frac{(M - \\mu)}{S_{M}} $ \n",
    "5. Reject or fail to reject null hypothesis by comparing the scores from steps 3 and 4.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Cohen's d and t test with a single sample<\\center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a little trick. For the t test we used the standard deviation of the distribution of means. However, when calculating Cohen's d, we use an estimate of the population standard deviation. We calculate $S$ like so:\n",
    "   - $ S = \\sqrt{S^2} $\n",
    "\n",
    "Thus, we calculate cohen's d like so:\n",
    "   - $ d = \\frac{M-\\mu}{S} $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean = 3.25\n",
      "Σ SS = 8.75\n",
      "S^2 = 2.9166666666666665\n",
      "variance of the distribution of means =  0.7291666666666666\n",
      "standard deviation of the distribution of means = 0.8539125638299665\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores X</th>\n",
       "      <th>mean M</th>\n",
       "      <th>deviation scores (X-M)</th>\n",
       "      <th>squared deviation scores (X-M)^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.25</td>\n",
       "      <td>-2.25</td>\n",
       "      <td>5.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1.75</td>\n",
       "      <td>3.0625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   scores X  mean M  deviation scores (X-M)  squared deviation scores (X-M)^2\n",
       "0         1    3.25                   -2.25                            5.0625\n",
       "1         3    3.25                   -0.25                            0.0625\n",
       "2         4    3.25                    0.75                            0.5625\n",
       "3         5    3.25                    1.75                            3.0625"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "scores = [1,3,4,5]\n",
    "\n",
    "def t_test_variance(scores):\n",
    "    mean=np.mean(scores)\n",
    "    deg_freedom=(len(scores)-1)\n",
    "    deviation_score=[x-mean for x in scores]\n",
    "    squared_deviation_scores=[x**2 for x in deviation_score]\n",
    "    sum_of_squared_deviation_scores=sum(squared_deviation_scores)\n",
    "    estimated_population_variance=sum_of_squared_deviation_scores/deg_freedom\n",
    "    variance_of_dist_of_means=estimated_population_variance/len(scores)\n",
    "    standard_deviation_of_dist_of_means=variance_of_dist_of_means**0.5\n",
    "    mean_fill=[np.mean(scores) for x in scores]\n",
    "    variance_dict={'scores X': scores, 'mean M': mean_fill, 'deviation scores (X-M)': deviation_score, \n",
    "                  'squared deviation scores (X-M)^2': squared_deviation_scores}\n",
    "    variance_df=pd.DataFrame(variance_dict)\n",
    "    print('mean =',mean)\n",
    "    print('\\u03A3 SS =', sum_of_squared_deviation_scores)\n",
    "    print('S^2 =',estimated_population_variance)\n",
    "    print('variance of the distribution of means = ', variance_of_dist_of_means)\n",
    "    print('standard deviation of the distribution of means =', standard_deviation_of_dist_of_means)\n",
    "    return variance_df\n",
    "\n",
    "t_test_variance(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean = 6.166666666666667\n",
      "Σ SS = 154.83333333333331\n",
      "S^2 = 30.96666666666666\n",
      "variance of the distribution of means =  5.1611111111111105\n",
      "standard deviation of the distribution of means = 2.2718078948518317\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores X</th>\n",
       "      <th>mean M</th>\n",
       "      <th>deviation scores (X-M)</th>\n",
       "      <th>squared deviation scores (X-M)^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>-5.166667</td>\n",
       "      <td>26.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>-4.166667</td>\n",
       "      <td>17.361111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>-4.166667</td>\n",
       "      <td>17.361111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>14.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>8.833333</td>\n",
       "      <td>78.027778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   scores X    mean M  deviation scores (X-M)  \\\n",
       "0         1  6.166667               -5.166667   \n",
       "1         2  6.166667               -4.166667   \n",
       "2         2  6.166667               -4.166667   \n",
       "3         7  6.166667                0.833333   \n",
       "4        10  6.166667                3.833333   \n",
       "5        15  6.166667                8.833333   \n",
       "\n",
       "   squared deviation scores (X-M)^2  \n",
       "0                         26.694444  \n",
       "1                         17.361111  \n",
       "2                         17.361111  \n",
       "3                          0.694444  \n",
       "4                         14.694444  \n",
       "5                         78.027778  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = [1,2,2,7,10,15]\n",
    "t_test_variance(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t test for dependent means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These kinds of tests are often used in repeated measures design when you have multiple scores for a participant within a subject design.\n",
    "\n",
    "One of the largest distinguishing characteristics of the t test for dependent means is the use of ***Difference scores***: the difference between one person's score on task 1 vs task 2. \n",
    "\n",
    "Let's say you work in a lab that studies the organizational properties of memory (completely hypothetically and not like the author of this notebook at all. Stop assuming things about me). In one experiment you have participants study a list of words and the recall them. In the first half of the experiment, you have participants study words with high measures of relatedness. In a second half you have words with low measures of word relatedness. You might run a t test for dependent means on the scores between the first half of the experiment and the second half. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> How do I conduct a t test for dependent means? </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Restate the question as a research hypothesis and a null hypothesis about the populations.\n",
    "2. Determine the characteristics of the comparison distribution.\n",
    "    - Make each person's two scores into a difference score. Do all the remaining steps using these difference scores.\n",
    "    - Figure the mean of these difference scores.\n",
    "    - Assume the mean of the distribution of means of difference scores of 0: $\\mu=0$\n",
    "    - The standard deviation of the distribution of the means of difference scores is figured as follows:\n",
    "        - Figure the estimated population variance of difference scores\n",
    "            - $ S^{2} = \\frac{SS}{df} $\n",
    "        - Figure the variance of the distribution of means of difference scores:\n",
    "            -  $ S^{2}_{M} = \\frac{S^{2}}{N} $\n",
    "        - Figure the standard deviation of the distrubution of means of difference scores:\n",
    "            - $ S_{M} = \\sqrt{S^{2}_{M}} $\n",
    "    - The shape is a t distribution with df = N -1 \n",
    "3. Determine the cutoff sample score on the compariosn distribution at which the null hypothesis should be rejected.\n",
    "    - Determine the significance level and whether to use a one tailed or two tailed hypothesis test.\n",
    "    - Look up the appropriate cutt off in a t table.\n",
    "4. Determine your sample's score on the comparison distribution \n",
    "    - $ t = \\frac{(M - \\mu)}{S_{M}} $\n",
    "5. Decide whether to reject the null hyporhesis by comparing steps 3 and 4. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When calculating Cohen's d, we use an estimate of the population standard deviation. We calculate $S$ like so:\n",
    "   - $ S = \\sqrt{S^2} $\n",
    "\n",
    "Thus, we calculate cohen's d like so:\n",
    "   - $ d = \\frac{M-\\mu}{S} $\n",
    "\n",
    "In reality, most of the time $ \\mu = 0 $ so it often reduces to:\n",
    "   - $ d = \\frac{M}{S} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Asumptions of the single sample t test and the dependent means t test\n",
    "\n",
    "- We assume that the population distribution is normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t test for Independent means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the t test for independent means, there are two seperate groups of people tested and in which the population variance is not known."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> How do I conduct a t test for a single sample? </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Restate the question as a research hypothesis and a null hypothesis about the populations.\n",
    "2. Determine the characteristics of the comparison distribution.\n",
    "    - The mean of the comparison distribution is 0. $ \\mu = 0 $\n",
    "    - Figure its standard deviation.\n",
    "        - Figure the estimated population varainces based on each sample. For each population:\n",
    "            - $ S^{2} = \\frac{SS}{N-1} $\n",
    "        - Figure the pooled estimate of the population variance:\n",
    "            - $ S^{2}_{Pooled} = \\frac{df_{1}}{df_{total}} S^{2}_{1} + \\frac{df_{2}}{df_{total}} S^{2}_{2} $\n",
    "        - Figure the variance of each distribution of means:\n",
    "            - $ S^{2}_{M_{1}} = \\frac{S^{2}_{Pooled}}{N_{1}} $\n",
    "            - $ S^{2}_{M_{2}} = \\frac{S^{2}_{Pooled}}{N_{2}} $\n",
    "        - Figure the variance of the distribution of differences between means: \n",
    "            - $ S^{2}_{Difference} = S^{2}_{M_{1}} + S^{2}_{M_{2}} $\n",
    "        - Figure the standard deviation of the distribution of the distribution of differences between means:\n",
    "            - $ S_{Difference} = \\sqrt{S^{2}_{Difference}} $\n",
    "    - Determine its shape: It will be a t distribution with $ df_{Total} $ degrees of freedom. \n",
    "3. Determine the cutoff sample score of the comparison distribution at which the null hypothesis should be rejected. \n",
    "    - Determine the degrees of freedom ($df_{Total}$), desired significance level, and tails in the test (one or two).\n",
    "    - Look up the appropriate cutoff in a t table. If the exact *df* is not given, use the *df* below it.\n",
    "4. Determine your sample's score on the comparison distribution:\n",
    "    - $ t = \\frac{(M_{1} - M_{2})}{S_{Difference}} $\n",
    "5. Decide whether to reject the null hypothesis: Compare the scores from steps 3 and 4. \n",
    "\n",
    " Note: if you're using the confidence interval method, you want to use $ M_{Difference} $. That brings our fomula to:\n",
    " - $ CI =  \\pm [(S_{Difference})*(t_{critical})] + M_{Difference} $ \n",
    " \n",
    "<center> Cohen's d and the independent means t test <\\center>\n",
    "\n",
    "The independent means t test uses:\n",
    "- $ d = \\frac{M_{1} - M_{2}}{S_{pooled}} $\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Asumptions of the independent means t test\n",
    "\n",
    "- Variance follows a normal distribution\n",
    "- Two populations have the same variance (homogeniethy of variance)\n",
    "- (implied but the means are independent)\n",
    "\n",
    "If one of these or both assumptions is incorrect, our t test results can be misleading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "199+266"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_variance(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3: Low Constraint Methods and Differential and Correlational Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***Field Research***: generally, focusing behavior that is n aturally occuring under largerly natural conditions.\n",
    "    - Below are some categories of field research:\n",
    "        - ***Naturualistic observiation***: observation of events as they occur in natural settings\n",
    "        - ***Archival research***: studying information from existing records made in natual settings.\n",
    "        - ***Surveys***: Asking  direct questions of people in natural settings.\n",
    "        - ***Case studies***: Making extensive observations of an individual or small group of individuals\n",
    "        - ***Program evaluation***: Conducting evaluations of applied procedures in natural settings\n",
    "        - ***Field experiments***: conducting experiments in natual settings in order to understand caustal relationships among variables.\n",
    "**Value of low constraint research:**        \n",
    "- Field research has high generalizibalitiy to the general population. Testing generalizability. However, it trades that for low external validity because it is hard to control.\n",
    "- Good for exposing yourself to new research\n",
    "- Demonstrating feasibilitry\n",
    "**Classification of observers in low constraint methods:**\n",
    "- ***An unobstrusive observer***: tries to avoid influencing the participant\n",
    "- ***Participant observer***: the researcher becomes part of the situation and may even contribute to it.\n",
    "    - The use of this kind of observer is what turns naturalistic observation into a case study.\n",
    "**Problems with low contraint methods**\n",
    "- ***Measurement reactivity:*** the phenomenon of participants behaving differently when they're being observed. \n",
    "    - ***Reactive measures*** are prone to distortion \n",
    "    - ***non-reactive measures*** are not prone to distortion\n",
    "- ***Habituation***: reducing the process of participants becoming less responsive to a stimulus after it is present \n",
    "- ***Unobtrusive measures***: are measures of behavior that are not obvious to pthe participants being ovserved and therefore are less likely to inffluence participants.\n",
    "    - ***Coding data***: scores are assigned to behavior. It is like taking an opperation definition and then converting it into numerical data. For example, slapping someone is a 3 on my made up aggression scale.\n",
    "    - ***Narative data:*** is self reported data.\n",
    "    - ***Selective surrival:*** archival research data is not always repersentative\n",
    "    - ***Content analysis***: examines records and identifies categoeis of events.\n",
    "- ***Representativeness***: how closely a sample ressembles the population under study.\n",
    "    - In low constraint research, there is usually low representativeness, which is one of its largest limitatiions\n",
    "- ***Generalizing***: the claim that a sample's results extend to the populations.\n",
    "- Establisting causation needs 3 conditions:\n",
    "    1. Covariation of events\n",
    "    2. Time order relationships\n",
    "    3. Alternative explanations are ruled out.\n",
    "- ***Experimenter reactivity***: any action by researchers that tends to influence the respoinses of participants. \n",
    "- ***Experimenter bias***: any impact the researcher's expectations might have on the observations or recordings of those behaviors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Validity and Threats to Validity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The textbook and our class discusses multiple kinds of validity. They are:\n",
    "- ***Statistical validity***: the accuracy of the p-value on which a statistical decision is based. \n",
    "    - Threats to statistical malidity include measurements and violations of underlying assumpitons of our stats tests.\n",
    "- ***Construct validity***: how well a study's results support the theory or construct behind the research and whether the theory supported by the findings provides the best avalible explanation of results. \n",
    "- ***External validity***: the degree to which the fresearchers are able to generalize the results to other participants, conditions, time and places.\n",
    "    - ***Limits of generalization***: the conditions in which a theory or scientific finding no longer validly applies.\n",
    "    - ***Ecological validity***: is used to refer to the appropriate generalizations from the lab to real-life situations.\n",
    "- ***Internal valitiy***: Internal valdity is the researcher's ability to control for possible confounding variables. It asks \"Was the independent variable–and not some extranious varible–responsible for the changes in the dependent varibale?\"\n",
    "    - Varibales that impact internal validity are confounding variables.\n",
    "\n",
    "There are lots of threats to internal validity. For a variable to be a confounding variable in must:\n",
    "    1. Vary with the independent variable \n",
    "    2. Have no effect on the dependent variable.\n",
    "\n",
    "Here are some common/major confounding varibles. Stay on the look out for them!\n",
    "- ***Maturation***: the process of natural growth overtime.\n",
    "    - This is vary common in longitudinal studies. \n",
    "- ***History***: events that are independent of the study that can affect the outcome.\n",
    "    - Threats increase woth longer pretest and posttest measures.\n",
    "- ***Testing***: participants gain proficiency through practice of the measurment instruments.\n",
    "- ***Instrumentation***: pre-test posttest changes may be due to changes in the measuring instrument, rather than the IV. \n",
    "- ***Regression to the mean***: Whenever we select participants because of their extreme scores, they will tend to be less extreme the second time around.\n",
    "- ***Selection***: when the groups under study are not equivelent before manipulation.\n",
    "- ***Attrition***: When the particcipants are lost at different rates for some reason.\n",
    "- ***Diffusion of treatment***: When participants communicate about the nature of experiment.\n",
    "- ***Sequence effects***: Particiopants experience with earlier conditions of the study affect their responses to later conditions.\n",
    "    - Applies in repeated measures designs\n",
    "\n",
    "- ***Experimenter Effects***: any biasing effects in a study that are due to the actions of the researcher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 5: Addressing Threats to Validity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are four major control group procedures:\n",
    "    1. general control procedures\n",
    "    2. Control of subject and experimenter effects\n",
    "    3. Control through participation selection and assignment\n",
    "    4. Control through experimental design\n",
    "\n",
    "*How do I control for subject and experimenter effects?*\n",
    "- Single and double-blind procedures, automation, objtive measures, multiple observers, and deception. \n",
    "\n",
    "- Participant selection methods such as random selection helps control threats to external validity.\n",
    "- Random assignment helps control internal validtiy.\n",
    "- Randomization is one of the most powerful control procedures. Randomize whenever possible.\n",
    "- Experiments rule out alternative hypothesis and test causual relationships. \n",
    "- The highest degree of control to protect internal validity is experimentation.\n",
    "- Most threats to calidity can be addressed with control groups, random selection, and random assignment.\n",
    "- Debriefing is necessary when there is deception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "441"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.randint(1,464)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "random.randint(1,464)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randint(1,464)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randint(1,464)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
